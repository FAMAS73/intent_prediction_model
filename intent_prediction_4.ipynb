{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocess:"
      ],
      "metadata": {
        "id": "PXnmhU-6SCsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vlQJjdGj5Ynm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, LayerNormalization, Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load intents file\n",
        "with open('intents.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess:\n"
      ],
      "metadata": {
        "id": "fZtX61zEAOGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data for training\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = {}\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses[intent['tag']] = intent['responses']\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Tokenization and sequence padding\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "max_len = max([len(sentence.split()) for sentence in training_sentences])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# One-hot encode labels\n",
        "label_index = dict((label, idx) for idx, label in enumerate(labels))\n",
        "training_labels = np.array([label_index[label] for label in training_labels])\n",
        "categorical_labels = to_categorical(training_labels, num_classes=num_classes)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, categorical_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7aYDD0tRFRac"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build and train model:"
      ],
      "metadata": {
        "id": "xbB6FRTNSKIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, LayerNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Input(shape=(max_len,)),\n",
        "    Embedding(input_dim=vocab_size, output_dim=100, mask_zero=True),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    LayerNormalization(),\n",
        "    LSTM(128),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    LayerNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    LayerNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=21, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "uWOzeZee5t8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment ว่าอะไรเป็นอะไร\n"
      ],
      "metadata": {
        "id": "guWAvFwHQhpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation:"
      ],
      "metadata": {
        "id": "c_lV8ANQdHSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Validation accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0HFYVgMTRxsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55143d7f-c43b-469f-cd7a-8b3b3ba6f1f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 20ms/step - loss: 3.4868 - accuracy: 0.3830\n",
            "Validation accuracy: 38.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model\n",
        "model.save('chatbot_model.h5')\n"
      ],
      "metadata": {
        "id": "n297OGB-n0zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b695ae32-8942-442a-814c-45a2900acb09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the Keras model\n",
        "model = tf.keras.models.load_model('chatbot_model.h5')\n",
        "\n",
        "# Configure the converter to use TensorFlow operations (SELECT_TF_OPS)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable TensorFlow ops.\n",
        "]\n",
        "\n",
        "# (Optional) Disable the experimental lowering of tensor list ops\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to file\n",
        "with open('chat_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model has been converted and saved.\")\n",
        "\n",
        "# Save tokenizer and label index\n",
        "with open('tokenizer.json', 'w') as f:\n",
        "    json.dump(tokenizer.to_json(), f)\n",
        "with open('label_index.json', 'w') as f:\n",
        "    json.dump(label_index, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfuijWlcwWFZ",
        "outputId": "7e2f3833-1e39-4c7c-dab9-558cee7430c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFLite model has been converted and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `responses` is already defined\n",
        "with open('responses.json', 'w') as responses_file:\n",
        "    json.dump(responses, responses_file)"
      ],
      "metadata": {
        "id": "2SnXulPS3-fl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(sentence.split()) for sentence in training_sentences])  # Example calculation\n",
        "\n",
        "with open('config.json', 'w') as config_file:\n",
        "    json.dump({'max_len': max_len}, config_file)"
      ],
      "metadata": {
        "id": "hQokwm6w4Igm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot function\n",
        "def chatbot_response(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
        "    prediction = model.predict(padded)[0]\n",
        "    tag = labels[np.argmax(prediction)]\n",
        "    return np.random.choice(responses[tag])\n",
        "\n",
        "# Example of interacting with the chatbot\n",
        "print(chatbot_response(\"Hi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnWD7r80mWbu",
        "outputId": "7c1b633f-c127-480b-8ae5-55947a89e842"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "Hi there. What brings you here today?\n"
          ]
        }
      ]
    }
  ]
}